{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb863da1",
   "metadata": {},
   "source": [
    "### Creating NeRF-Compatiable training data (transforms.json)\n",
    "#### Notebook Overview \n",
    "\n",
    "After doing feature mapping and feature extraction with COLMAP, we need to convert the extracted feature data into \n",
    "NeRF-Compatiable Format (aka transforms.json) to use in a training process.\n",
    "\n",
    "STEPS :\n",
    "1) Extract necessary data from associated COLMAP results - images.txt and cameras.txt\n",
    "2) Calculate the Homography matrix and create a transforms.json file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f65ed4",
   "metadata": {},
   "source": [
    "#### Parse COLMAP Results and Create NeRF-Compatible Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa786fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import os\n",
    "import cv2\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537f62c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse COLMAP camera parameters\n",
    "def parse_colmap_cameras(cameras_file):\n",
    "    cameras = {}\n",
    "    with open(cameras_file, \"r\") as f:\n",
    "        for line in f:\n",
    "            if line.startswith(\"#\"):\n",
    "                continue\n",
    "            items = line.strip().split()\n",
    "            if len(items) < 4:\n",
    "                continue\n",
    "\n",
    "            camera_id = int(items[0])\n",
    "            model = items[1]\n",
    "            width = int(items[2])\n",
    "            height = int(items[3])\n",
    "            params = np.array(list(map(float, items[4:])))\n",
    "\n",
    "            cameras[camera_id] = {\n",
    "                \"id\": camera_id,\n",
    "                \"model\": model,\n",
    "                \"width\": width,\n",
    "                \"height\": height,\n",
    "                \"params\": params\n",
    "            }\n",
    "    return cameras\n",
    "\n",
    "# Function to parse COLMAP image parameters (camera poses)\n",
    "def parse_colmap_images(images_file):\n",
    "    images = {}\n",
    "    with open(images_file, \"r\") as f:\n",
    "        i = 0\n",
    "        for line in f:\n",
    "            if line.startswith(\"#\"):\n",
    "                continue\n",
    "            if i == 0:  # Parse image data\n",
    "                items = line.strip().split()\n",
    "                image_id = int(items[0])\n",
    "                qw, qx, qy, qz = map(float, items[1:5])\n",
    "                tx, ty, tz = map(float, items[5:8])\n",
    "                camera_id = int(items[8])\n",
    "                image_name = items[9]\n",
    "\n",
    "                images[image_id] = {\n",
    "                    \"id\": image_id,\n",
    "                    \"qvec\": [qw, qx, qy, qz],\n",
    "                    \"tvec\": [tx, ty, tz],\n",
    "                    \"camera_id\": camera_id,\n",
    "                    \"name\": image_name,\n",
    "                    \"xys\": [],\n",
    "                    \"point3D_ids\": []\n",
    "                }\n",
    "                i = 1\n",
    "            elif i == 1:  # Parse observed points\n",
    "                i = 0\n",
    "    return images\n",
    "\n",
    "# Function to convert quaternion to rotation matrix\n",
    "def qvec2rotmat(qvec):\n",
    "    return np.array([\n",
    "        [1 - 2 * qvec[2]**2 - 2 * qvec[3]**2,\n",
    "         2 * qvec[1] * qvec[2] - 2 * qvec[0] * qvec[3],\n",
    "         2 * qvec[3] * qvec[1] + 2 * qvec[0] * qvec[2]],\n",
    "        [2 * qvec[1] * qvec[2] + 2 * qvec[0] * qvec[3],\n",
    "         1 - 2 * qvec[1]**2 - 2 * qvec[3]**2,\n",
    "         2 * qvec[2] * qvec[3] - 2 * qvec[0] * qvec[1]],\n",
    "        [2 * qvec[3] * qvec[1] - 2 * qvec[0] * qvec[2],\n",
    "         2 * qvec[2] * qvec[3] + 2 * qvec[0] * qvec[1],\n",
    "         1 - 2 * qvec[1]**2 - 2 * qvec[2]**2]])\n",
    "\n",
    "# Parse COLMAP output\n",
    "try:\n",
    "    camera_path = \"./data/sparse/0/cameras.txt\"\n",
    "    images_path = \"./data/sparse/0/images.txt\"\n",
    "    cameras = parse_colmap_cameras(camera_path)\n",
    "    images = parse_colmap_images(images_path)\n",
    "\n",
    "    print(f\"Found {len(cameras)} cameras and {len(images)} images\")\n",
    "\n",
    "    # Print example camera parameters\n",
    "    for camera_id, camera in list(cameras.items())[:1]:\n",
    "        print(f\"\\nCamera {camera_id}:\")\n",
    "        print(f\"  Model: {camera['model']}\")\n",
    "        print(f\"  Width x Height: {camera['width']} x {camera['height']}\")\n",
    "        print(f\"  Parameters: {camera['params']}\")\n",
    "\n",
    "    # Print example image parameters\n",
    "    for image_id, image in list(images.items())[:1]:\n",
    "        print(f\"\\nImage {image_id}: {image['name']}\")\n",
    "        print(f\"  Camera ID: {image['camera_id']}\")\n",
    "        print(f\"  Position: {image['tvec']}\")\n",
    "        print(f\"  Rotation (quaternion): {image['qvec']}\")\n",
    "\n",
    "        # Convert to transformation matrix\n",
    "        R = qvec2rotmat(image['qvec'])\n",
    "        t = np.array(image['tvec'])\n",
    "\n",
    "        # Create camera-to-world transformation matrix\n",
    "        c2w = np.eye(4)\n",
    "        c2w[:3, :3] = R\n",
    "        c2w[:3, 3] = t\n",
    "\n",
    "        print(\"  Transformation matrix (camera-to-world):\")\n",
    "        print(c2w)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error parsing COLMAP output: {e}\")\n",
    "    print(\"This might indicate that COLMAP failed to reconstruct the scene.\")\n",
    "    print(\"Try adjusting parameters or checking if the video contains enough distinct features.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cac5b46",
   "metadata": {},
   "source": [
    " #### Create NeRF-Compatible Transforms JSON File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c8574b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def create_transforms_json(cameras, images, output_file=\"./data/transforms.json\"):\n",
    "    \"\"\"Create a transforms.json file for NeRF training\"\"\"\n",
    "\n",
    "    # Get the camera parameters from the first camera\n",
    "    # Assuming all frames use the same camera\n",
    "    camera_id = list(cameras.keys())[0]\n",
    "    camera = cameras[camera_id]\n",
    "\n",
    "    # For OPENCV camera model, the parameters are [fx, fy, cx, cy, k1, k2, p1, p2]\n",
    "    # Extract focal length and principal point\n",
    "    fx = camera['params'][0]\n",
    "    fy = camera['params'][1]\n",
    "    cx = camera['params'][2]\n",
    "    cy = camera['params'][3]\n",
    "\n",
    "    # Average focal length for simplicity\n",
    "    # focal = (fx + fy) / 2\n",
    "\n",
    "    frames = []\n",
    "    for image_id, image in images.items():\n",
    "        # Convert quaternion to rotation matrix\n",
    "        R = qvec2rotmat(image['qvec'])\n",
    "        t = np.array(image['tvec'])\n",
    "\n",
    "        # Create camera-to-world transformation matrix\n",
    "        c2w = np.eye(4)\n",
    "        c2w[:3, :3] = R\n",
    "        c2w[:3, 3] = t\n",
    "\n",
    "        frame = {\n",
    "            \"file_path\": \"./frames/\" + image['name'],\n",
    "            \"transform_matrix\": c2w.tolist(),\n",
    "        }\n",
    "        frames.append(frame)\n",
    "\n",
    "    # Create the full transforms dictionary\n",
    "    transforms = {\n",
    "        \"camera_angle_x\": 2 * np.arctan(camera['width'] / (2 * fx)),\n",
    "        \"camera_angle_y\": 2 * np.arctan(camera['height'] / (2 * fy)),\n",
    "        \"fl_x\": fx,\n",
    "        \"fl_y\": fy,\n",
    "        \"cx\": cx,\n",
    "        \"cy\": cy,\n",
    "        \"w\": camera['width'],\n",
    "        \"h\": camera['height'],\n",
    "        \"frames\": frames\n",
    "    }\n",
    "\n",
    "    # Save to file\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(transforms, f, indent=2)\n",
    "\n",
    "    return transforms\n",
    "\n",
    "# Create transforms.json\n",
    "try:\n",
    "    transforms = create_transforms_json(cameras, images)\n",
    "    print(\"Created transforms.json\")\n",
    "\n",
    "    # Display the first few frames\n",
    "    print(\"\\nFirst frame transform:\")\n",
    "    print(json.dumps(transforms[\"frames\"][0], indent=2))\n",
    "\n",
    "    # Download the transforms.json file for later use\n",
    "    files.download(\"transforms.json\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error creating transforms.json: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
